{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\cftfda01\\\\Documents\\\\SBST Train IAMS Project\\\\scripts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Inspect results\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\cftfda01\\\\Documents\\\\SBST Train IAMS Project\\\\alarm-event-logs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define root file directory folder where the files are being stored\n",
    "#os.chdir(cwd + alarmLoc)\n",
    "os.chdir(os.path.dirname(os.getcwd()) + '\\\\alarm-event-logs')\n",
    "\n",
    "# Check current directory location\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Check directory location\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alarmLog.7z',\n",
       " 'alarmLog_expanded',\n",
       " 'dataCleaned',\n",
       " 'desktop.ini',\n",
       " 'dummyLog',\n",
       " 'dummyLog - Holding',\n",
       " 'DummyZip',\n",
       " 'eventLog.7z',\n",
       " 'eventLog_expanded',\n",
       " 'Original Sample from 27 Oct 2020 (simplified)',\n",
       " 'Repair Logs',\n",
       " 'Sample from 27 Oct 2020 (OG).zip',\n",
       " 'sample_data_ats',\n",
       " 'sample_data_ats.zip',\n",
       " 'sample_data_cms',\n",
       " 'sample_data_cms - test',\n",
       " 'sample_data_cms.zip',\n",
       " 'sample_data_ecs',\n",
       " 'sample_data_ecs.zip',\n",
       " 'testLog']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect files in directory\n",
    "fileList = os.listdir()\n",
    "fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of Alarm and Normal Event Files\n",
    "#targetFolder = '\\\\DummyZip\\\\testZip_Test - Copy'\n",
    "#targetFolder = '\\\\sample_data_ecs\\\\batch 001 - 20201230 to 20210201\\\\EventLogs'\n",
    "#targetFolder = '\\\\sample_data_cms\\\\batch 001 - 20201230 to 20210201\\\\AlarmLogs'\n",
    "targetFolder = '\\\\sample_data_test2\\\\batch 001 - 20201230 to 20210201\\\\TestLogs\\\\CMS-0000005'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\cftfda01\\\\Documents\\\\SBST Train IAMS Project\\\\alarm-event-logs\\\\sample_data_cms\\\\batch 001 - 20201230 to 20210201\\\\EventLogs'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define root file directory folder where the files are being stored\n",
    "os.chdir(cwd + targetFolder)\n",
    "\n",
    "# Check directory location\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect files in directory\n",
    "fileList = os.listdir()\n",
    "len(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get folder contents\n",
    "def list_files(dir):\n",
    "    fileDirList = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            fileDirList.append(os.path.join(root, name))\n",
    "    return fileDirList\n",
    "\n",
    "\n",
    "def list_files2(dir):\n",
    "    fileList = []\n",
    "    fileDirList = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            fileList.append(os.path.join(name))\n",
    "            fileDirList.append(os.path.join(root, name))\n",
    "    return fileList, fileDirList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of files with directory\n",
    "#fileList_Dir = list_files(os.getcwd())\n",
    "\n",
    "# Inspect list of files\n",
    "#fileList_Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of files with directory\n",
    "#fileList_Dir2 = list_files2(os.getcwd())\n",
    "\n",
    "# Inspect list of files\n",
    "#fileList_Dir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexCounter = 0\n",
    "#print(fileList_Dir2[0][indexCounter])\n",
    "#print(fileList_Dir2[1][indexCounter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Strategy\n",
    "\n",
    "**Scenario**\n",
    "1. The folder may have a mix of many log files, .tar files and .tar.gz files in the thousands\n",
    "2. Each .tar and .tar.gz file may have varying levels of subfolders in the form of more .tar and .tar.gz files under them\n",
    "3. Extracting too many files to a single directory would cause the windows indexer to overwork, resulting in a severe slowdown in system performance\n",
    "4. Some log files are duplicates\n",
    "\n",
    "\n",
    "**Goal**\n",
    "1. Extract out all the log files from the corresponding multi-level .tar and .tar.gz files\n",
    "2. Bin the log files into smaller single level subdirectories of 50K files each\n",
    "3. Delete .tar and .tar.gz files once files have been extracted\n",
    "4. Remove duplicates\n",
    "\n",
    "**Plan**\n",
    "1. Initialise variables\n",
    "2. Create while loop to check for length of list of files within directory (including subdirectories) that contain .tar.gz or .tar files\n",
    "    1. Use os.walk to comb through directory and subdirectory for .tar.gz or .tar files\n",
    "    2. If each .tar.gz or .tar file is found\n",
    "        1. Extract a file to a new unique folder as a subfolder to the main parent directory\n",
    "        2. Delete original file once extraction has been completed\n",
    "        3. Update counter\n",
    "    3. Use os.walk to comb through directory for any empty subfolders (this is caused by the child elements being .tar.gz or .tar files which were extracted out)\n",
    "    4. If a subfolder is found to be empty, delete the folder\n",
    "3. Repeat Step 2 till there are no more .tar.gz or .tar files\n",
    "\n",
    "**Note**\n",
    "1. Duplicates would only be overwritten if the files are written to a common directory\n",
    "2. Additional  duplicate removal needs to be done when all the processed files are merged\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cftfda01\\Documents\\SBST Train IAMS Project\\alarm-event-logs\\sample_data_cms\\batch 001 - 20201230 to 20210201\\EventLogs\n",
      "Commence Extraction Run: 1\n",
      "Batch started on: Thu Mar 18 13:24:35 2021\n",
      "Completed Extraction Run: 1\n",
      "Batch completed on: Thu Mar 18 14:14:59 2021\n",
      "\n",
      "Commence Extraction Run: 2\n",
      "Batch started on: Thu Mar 18 14:15:16 2021\n",
      "Completed Extraction Run: 2\n",
      "Batch completed on: Thu Mar 18 15:35:35 2021\n",
      "\n",
      "Commence file and folder clean up\n",
      "File and folder clean up complete\n",
      "\n",
      "Extraction Complete\n",
      "End Time: Thu Mar 18 15:40:17 2021\n",
      "Execution time in seconds: 8141.939615249634\n",
      "Execution time in minutes: 135.6989935874939\n",
      "Execution time in hours: 2.2616498931248983\n"
     ]
    }
   ],
   "source": [
    "# Start timer\n",
    "startTime = time.time()\n",
    "\n",
    "# Get List of .tar.gz and .tar files\n",
    "docType_targz = \".tar.gz\"\n",
    "docType_tar = \".tar\"\n",
    "\n",
    "# Get Current Directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Need to update counter with each run\n",
    "# 899,999,999 possible subfolders can be created\n",
    "counter = 100000001\n",
    "runCounter = 1\n",
    "\n",
    "# Repeat function till there are no more .tar.gz or .tar files in directory and subfolders\n",
    "while len([s for s in list_files(os.getcwd()) if (s.endswith(docType_targz) | s.endswith(docType_tar))]) > 0:\n",
    "    \n",
    "    print(\"Commence Extraction Run: \" + str(runCounter))\n",
    "    print(\"Batch started on: \" + time.ctime(time.time()))\n",
    "    \n",
    "    # Get list of files & their directories\n",
    "    for dirpath, dir, files in os.walk(os.getcwd()):    \n",
    "        # Loop through each file\n",
    "        for file in files:\n",
    "            # Get file directory of each file\n",
    "            filepath = dirpath + os.sep + file\n",
    "            \n",
    "            # target only specific doctypes\n",
    "            if filepath.endswith(docType_targz ) | file.endswith(docType_tar):\n",
    "                # Create Directory for Output Files Generated\n",
    "                outputDirName = \"output - \" + str(counter)\n",
    "                # Create directory at the 2nd level\n",
    "                Path(\"/\" + outputDirName).mkdir(parents=True, exist_ok=True)\n",
    "                #os.makedirs(dirpath + os.sep + outputDirName)\n",
    "                \n",
    "                # Update counter\n",
    "                counter = counter + 1\n",
    "\n",
    "                # Extract File\n",
    "                tar = tarfile.open(filepath)\n",
    "                tar.extractall(outputDirName)\n",
    "                tar.close()\n",
    "\n",
    "                # Delete file\n",
    "                os.remove(filepath)\n",
    "    \n",
    "    # Print Current Time\n",
    "    print(\"Completed Extraction Run: \" + str(runCounter))\n",
    "    print(\"Batch completed on: \" + time.ctime(time.time()))\n",
    "    print()\n",
    "    \n",
    "    # Update counter\n",
    "    runCounter = runCounter + 1\n",
    "\n",
    "print(\"Commence file and folder clean up\")\n",
    "# Remove duplicate files with the same name spread across multiple subfolders\n",
    "# Generate list of files and subdirectories\n",
    "fileList_Dir2 = list_files2(os.getcwd())\n",
    "# Initate variables\n",
    "#trialFileList = [] # depreciated as the use of sets is significantly faster for longer lists\n",
    "trialFileSet = set()\n",
    "indexCounter = 0\n",
    "for file in fileList_Dir2[0]:\n",
    "    #if file in trialFileList: # depreciated as the use of sets is significantly faster for longer lists\n",
    "    if file in trialFileSet:\n",
    "        # Delete file if a duplicate is found\n",
    "        os.remove(fileList_Dir2[1][indexCounter])\n",
    "        #Update counter\n",
    "        indexCounter = indexCounter + 1\n",
    "    else:\n",
    "        # Update Trial List/Set\n",
    "        #trialFileList.append(file) # depreciated as the use of sets is significantly faster for longer lists\n",
    "        trialFileSet.add(file)\n",
    "        #Update counter\n",
    "        indexCounter = indexCounter + 1\n",
    "\n",
    "    \n",
    "# Remove empty folders\n",
    "folders = list(os.walk(os.getcwd()))[1:]\n",
    "\n",
    "for folder in folders:\n",
    "    # Check if folder is empty\n",
    "    if not folder[2]:\n",
    "        # Delete folder\n",
    "        os.rmdir(folder[0])\n",
    "        \n",
    "print(\"File and folder clean up complete\")\n",
    "print()\n",
    "        \n",
    "# Stop Timer\n",
    "endTime = time.time()\n",
    "executionTime = (endTime - startTime)\n",
    "\n",
    "# Print Timing\n",
    "print(\"Extraction Complete\")\n",
    "print(\"End Time: \" + time.ctime(endTime))\n",
    "print('Execution time in seconds: ' + str(executionTime))\n",
    "print('Execution time in minutes: ' + str(executionTime/60))\n",
    "print('Execution time in hours: ' + str(executionTime/60/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3353925"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate list of files with directory\n",
    "fileList_Dir = list_files(os.getcwd())\n",
    "\n",
    "# Inspect list of files\n",
    "len(fileList_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
